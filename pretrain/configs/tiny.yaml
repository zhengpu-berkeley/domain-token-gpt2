# Tiny model configuration for smoke testing
# Runs quickly on CPU/MPS for local development

# Model architecture (tiny GPT)
model:
  n_layer: 4
  n_head: 4
  n_embd: 128
  block_size: 256

# Training settings
training:
  # Batch sizes
  batch_size: 4  # micro batch size
  total_batch_size: 4096  # total tokens per step (B * T * grad_accum_steps = 4 * 256 * 4)
  
  # Training duration
  max_steps: 100  # small for smoke test
  warmup_steps: 10
  
  # Learning rate
  max_lr: 1.0e-3
  min_lr: 1.0e-4
  
  # Regularization
  weight_decay: 0.1
  grad_clip: 1.0
  
  # Precision
  dtype: float32  # use float32 for CPU/MPS compatibility

# Evaluation
eval:
  interval: 20  # evaluate every N steps
  val_steps: 5  # number of val batches to average

# Logging
logging:
  interval: 10  # log every N steps

# Checkpointing
checkpoint:
  interval: 50  # save every N steps
  save_final: true

